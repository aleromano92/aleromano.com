---
title: "The Boys parla del futuro con le super AI"
description: "Un'analisi dei rischi dell'AI ispirata dal saggio di Dario Amodei, tracciando un parallelo con i supereroi della serie The Boys."
pubDate: 2026-01-31
author: "Alessandro Romano"
tags: ["AI", "Security"]
language: "it"
image:
  url: ../../../assets/blog/the-boys-future-super-ai/featured.png
  alt: "I supereroi di The Boys governati dalle AI"
---

L'ispirazione per questo post nasce dalla lettura del saggio di Dario Amodei, [The Adolescence of Technology](https://darioamodei.com/essay/the-adolescence-of-technology). La prima sezione del saggio si concentra sull'analizzare in modo fattuale i veri rischi che l'AI pu√≤ portare. E no, non sono la scomparsa di alcuni lavori, o almeno questi non sono i pericoli pi√π imminenti o catastrofici. I rischi maggiori sono collegati ad eventuali danni biologici che si possono realizzare con la prossima generazione di modelli.

## Il Parallelo con The Boys üíâ

C'√® una frase nel saggio che mi ha colpito particolarmente:

> "To put it another way, renting a powerful AI gives intelligence to malicious (but otherwise average) people."

Questa affermazione mi ha immediatamente fatto pensare al fumetto e alla serie TV *The Boys*, dove un'azienda privata, la Vought America, ha donato i superpoteri a persone normalissime tramite un composto chimico (il Composto V). Il risultato? Supereroi "cazzoni" che abusano dei loro poteri o, peggio, creano dei veri e propri disastri. In particolare, il fumetto racconta di alcuni episodi in cui la Vought ha pressato il governo per inserire i superuomini nelle operazioni militari. L'esito √® stato un vero disastro, con perdite di vite umane inenarrabili, poich√© i supereroi non erano assolutamente addestrati alla guerra e alle sue regole, portando solo caos e distruzione collaterale.

## Il Cast dei Super-AI ü¶∏‚Äç‚ôÇÔ∏è ü¶∏‚Äç‚ôÄÔ∏è üßî‚Äç‚ôÇÔ∏è ü¶π‚Äç‚ôÇÔ∏è ü¶π‚Äç‚ôÇÔ∏è

Prima di tornare ad esaminare cosa potremmo fare per evitare che uno scenario simile si avveri, permettetemi di aggiungere un altro livello a questo parallelo. Questa volta tra i super di The Boys e gli attuali modelli di AI:

*   **Il Patriota (Homelander) √® Grok**: Anarchico, fortissimo e senza freni inibitori. Non ha paura di andare oltre i limiti, con tutte le conseguenze distruttive del caso. Rappresenta la potenza senza controllo e la mancanza di responsabilit√† etica.
*   **Starlight √® Claude**: Si accorge dell'enorme problema che i "supereroi" pongono e vuole collaborare con le istituzioni per mettere un freno al loro strapotere. Cerca di fare la cosa giusta dall'interno, spingendo per la sicurezza e l'etica.
*   **Il Regolatore √® Butcher**: Avendo aspettato troppo a prendere delle contromisure, ora rischia di dover ricorrere alla "violenza" (metaforicamente, leggi draconiane o ban totali) e ai metodi pi√π efferati per riportare l'ordine. Se la politica dorme, il risveglio sar√† brusco e brutale come Billy Butcher.
*   **The Deep (Abisso) √® OpenAI**: Non me ne voglia OpenAI, ma il recente annuncio di mettere la pubblicit√† nelle sue risposte mi ha ricordato lo smarrito Abisso. Un tempo parte dei "Grandi", ora sembra cercare disperatamente di rimanere rilevante o profittevole, a volte con mosse che lasciano perplessi.
*   **Soldatino (Soldier Boy) √® Gemini**: Proprio come Soldier Boy era l'eroe numero uno prima di Patriota, Google (con DeepMind, AlphaGo, BERT) era il re indiscusso dell'AI prima che arrivasse l'hype di ChatGPT.
Soldier Boy non ha solo la forza bruta, ha quel raggio pettorale devastante che "brucia" il Composto V agli altri. Google ha una potenza computazionale (TPU, Data Center) e una base dati (YouTube, Search) che potrebbe tecnicamente "spegnere" o rendere obsoleti i competitor se decidesse di rilasciare tutto il suo arsenale senza freni etici.

![image](../../../assets/blog/the-boys-future-super-ai/super-ai.png)


## Torniamo ai rischi: uno scenario pratico ‚ò£Ô∏è

Amodei sottolinea come la prossima generazione di modelli di AI avr√† capacit√† pratiche che andranno ben oltre la semplice generazione di testo o immagini. Questi modelli potranno eseguire compiti complessi, come progettare nuovi farmaci, creare materiali avanzati, o persino manipolare organismi biologici.

Immaginate lo spacciatore del parchetto con ambizioni da Pablo Escobar che si trova in mano uno strumento che gli consiglia passo dopo passo come portare avanti meglio la sua attivit√†: dalle tecniche avanzate per riciclare il denaro fino alla creazione di armi batteriologiche per ricattare i governi o eliminare la concorrenza.

Se pensate che stia esagerando perch√© "anche prima con Google avresti potuto farlo, le informazioni erano l√¨", vi sbagliate di grosso. Certo, i genomi e molte informazioni scientifiche sono pubblicamente disponibili, ma Google non ti ha mai dato la "conoscenza pratica" (tacit knowledge) per mettere insieme i pezzi in modo efficace. Gli LLM s√¨. Per approfondire, vi consiglio di leggere il report del Red Team di Anthropic sui rischi biologici: [Anthropic Red Team Report](https://red.anthropic.com/2025/biorisk/).

## Regolamentazione vs Far West üë®‚Äç‚öñÔ∏è ü§†

Amodei suggerisce che le AI companies dovrebbero collaborare e lavorare con i governi per stabilire una serie di "guard rail" per i modelli. Non si tratta di invocare una legislazione eccessiva e generica che soffochi l'innovazione, ma norme molto specifiche e mirate, da implementare man mano che nuovi rischi concreti emergono.

In questo contesto, Amodei sottolinea come Anthropic stia gi√† mettendo in piedi queste contromisure autonomamente, senza che nessun regolatore glielo abbia chiesto. Dall'altra parte, altre AI hanno gi√† dato prova di permettere abusi gravi, come la generazione di immagini di nudo non consenziente, incluse persone comuni e bambini ([vedi questo articolo del The Guardian](https://www.theguardian.com/commentisfree/2026/jan/09/grok-undressing-women-children-us-action)).

## Conclusione üßò‚Äç‚ôÇÔ∏è

Non vorrei vivere in un mondo in cui la politica debba creare i "Butcher" per fermare l'AI. Spero vivamente che i policy maker leggano con seriet√† questo saggio di Amodei e inizino a collaborare con le aziende in maniera seria.

Abbiamo bisogno di evitare l'over-regulation in stile "EU AI Act" preventivo su tutto, perch√© l'intera umanit√† ha bisogno del progresso che questa tecnologia pu√≤ portare (in medicina, scienza, energia). Ma allo stesso tempo, abbiamo disperatamente bisogno di una regolazione mirata, agile e basata sui fatti, non sulla paura o sull'ignoranza. Solo cos√¨ potremo avere i benefici dei superpoteri senza finire schiacciati dai danni collaterali della Vought.
